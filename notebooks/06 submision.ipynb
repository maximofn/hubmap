{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import load\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 1\n",
    "GPU = True\n",
    "DIM = 300\n",
    "SEARCH_BS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_images',\n",
       " 'test_images',\n",
       " 'train_annotations',\n",
       " 'train.csv',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"../\")\n",
    "data_path = path/\"data\"\n",
    "train_images_path = data_path / \"train_images\"\n",
    "test_images_path = data_path / \"test_images\"\n",
    "output_path = Path(\"./\")\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02_unet_custom_DataParallel.pth',\n",
       " '02_unet_custom_DataParallel.zip',\n",
       " '08_Resnet18_finders_and_fastprogress.pth',\n",
       " '07_unet_resnet50_DataParallel.zip',\n",
       " '08_Resnet18_finders_and_fastprogress.zip',\n",
       " '07_unet_resnet50_DataParallel.pth',\n",
       " '01_unet_custom_model.pth',\n",
       " '08_unet_resnet50_DataParallel.zip',\n",
       " '01_unet_custom_weigths.pth',\n",
       " '08_unet_resnet50_DataParallel.pth']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path = Path(\"../models\")\n",
    "os.listdir(models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10044.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10274.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10392.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10488.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10610</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/train_images/10610.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     organ data_source  img_height  img_width  pixel_size  \\\n",
       "0  10044  prostate         HPA        3000       3000         0.4   \n",
       "1  10274  prostate         HPA        3000       3000         0.4   \n",
       "2  10392    spleen         HPA        3000       3000         0.4   \n",
       "3  10488      lung         HPA        3000       3000         0.4   \n",
       "4  10610    spleen         HPA        3000       3000         0.4   \n",
       "\n",
       "   tissue_thickness                                                rle   age  \\\n",
       "0                 4  1459676 77 1462675 82 1465674 87 1468673 92 14...  37.0   \n",
       "1                 4  715707 2 718705 8 721703 11 724701 18 727692 3...  76.0   \n",
       "2                 4  1228631 20 1231629 24 1234624 40 1237623 47 12...  82.0   \n",
       "3                 4  3446519 15 3449517 17 3452514 20 3455510 24 34...  78.0   \n",
       "4                 4  478925 68 481909 87 484893 105 487863 154 4908...  21.0   \n",
       "\n",
       "      sex                             path  \n",
       "0    Male  ../data/train_images/10044.tiff  \n",
       "1    Male  ../data/train_images/10274.tiff  \n",
       "2    Male  ../data/train_images/10392.tiff  \n",
       "3    Male  ../data/train_images/10488.tiff  \n",
       "4  Female  ../data/train_images/10610.tiff  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_path / \"train.csv\")\n",
    "train_df['path'] = train_df.id.apply(lambda x: f'{str(train_images_path)}/{x}.tiff')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 2 # 2 classes\n",
    "number_of_channels = 3\n",
    "\n",
    "def conv3x3_bn(ci, co):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(ci, co, 3, padding=1),\n",
    "        torch.nn.BatchNorm2d(co),\n",
    "        torch.nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def encoder_conv(ci, co):\n",
    "  return torch.nn.Sequential(\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        conv3x3_bn(ci, co),\n",
    "        conv3x3_bn(co, co),\n",
    "    )\n",
    "\n",
    "class deconv(torch.nn.Module):\n",
    "    def __init__(self, ci, co):\n",
    "        super(deconv, self).__init__()\n",
    "        self.upsample = torch.nn.ConvTranspose2d(ci, co, 2, stride=2)\n",
    "        self.conv1 = conv3x3_bn(ci, co)\n",
    "        self.conv2 = conv3x3_bn(co, co)\n",
    "    \n",
    "    # recibe la salida de la capa anetrior y la salida de la etapa\n",
    "    # correspondiente del encoder\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX, 0, diffY, 0))\n",
    "        # concatenamos los tensores\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class out_conv(torch.nn.Module):\n",
    "    def __init__(self, ci, co, coo):\n",
    "        super(out_conv, self).__init__()\n",
    "        self.upsample = torch.nn.ConvTranspose2d(ci, co, 2, stride=2)\n",
    "        self.conv = conv3x3_bn(ci, co)\n",
    "        self.final = torch.nn.Conv2d(co, coo, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX, 0, diffY, 0))\n",
    "        x = self.conv(x1)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "class UNetResnet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=number_of_classes, in_ch=number_of_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)           \n",
    "        if in_ch != 3:\n",
    "          self.encoder.conv1 = torch.nn.Conv2d(in_ch, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.deconv1 = deconv(512,256)\n",
    "        self.deconv2 = deconv(256,128)\n",
    "        self.deconv3 = deconv(128,64)\n",
    "        self.out = out_conv(64, 64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x_in = torch.tensor(x.clone().detach())\n",
    "        x_in = x.clone().detach()\n",
    "        x = self.encoder.relu(self.encoder.bn1(self.encoder.conv1(x)))\n",
    "        x1 = self.encoder.layer1(x)\n",
    "        x2 = self.encoder.layer2(x1)\n",
    "        x3 = self.encoder.layer3(x2)\n",
    "        x = self.encoder.layer4(x3)\n",
    "        x = self.deconv1(x, x3)\n",
    "        x = self.deconv2(x, x2)\n",
    "        x = self.deconv3(x, x1)\n",
    "        x = self.out(x, x_in)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice coeficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(1)\n",
    "    m1 = pred.view(num, -1).float()  # Flatten\n",
    "    m2 = target.view(num, -1).float()  # Flatten\n",
    "    intersection = (m1 * m2).sum().float()\n",
    "    dice = (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)\n",
    "    dice = dice.item()\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [\n",
    "        np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])\n",
    "    ]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = 1\n",
    "    if len(shape) == 3:\n",
    "        img = img.reshape(shape[0], shape[1])\n",
    "    else:\n",
    "        img = img.reshape(shape[0], shape[1])\n",
    "    return img.T\n",
    "\n",
    "def mask2rle(mask):\n",
    "    '''\n",
    "    mask: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def calc_mask(tensor, model):\n",
    "    '''\n",
    "    tensor: tensor of shape (1, 3, H, W)\n",
    "    Returns mask of shape (H, W)\n",
    "    '''\n",
    "    if len(tensor.shape) == 3:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if GPU:\n",
    "            tensor = tensor.to(device)\n",
    "            model.to(device)\n",
    "        else:\n",
    "            print(\"CPU\")\n",
    "        output = model(tensor).squeeze(0)\n",
    "        pred_mask = torch.argmax(output, axis=0)\n",
    "    return pred_mask.detach().cpu().numpy()\n",
    "\n",
    "def calc_mask_from_image_path(img_path, model):\n",
    "    '''\n",
    "    img_path: path to image\n",
    "    model: model to use for inference\n",
    "    Returns mask of shape (H, W)\n",
    "    '''\n",
    "    img = cv2.imread(img_path, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    img_tensor = torch.from_numpy(img.astype(np.float32)).float().permute(2, 0, 1).unsqueeze(0)\n",
    "    return calc_mask(img_tensor, model)\n",
    "\n",
    "def calc_rle_from_image_path(img_path, model):\n",
    "    '''\n",
    "    img_path: path to image\n",
    "    model: model to use for inference\n",
    "    Returns rle string\n",
    "    '''\n",
    "    mask = calc_mask_from_image_path(img_path, model)\n",
    "    return mask2rle(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, dataframe, n_classes=2, dim=None, interpolation=cv2.INTER_LANCZOS4):\n",
    "    self.dataframe = dataframe\n",
    "    self.n_classes = n_classes\n",
    "    self.dim = dim\n",
    "    self.interpolation = interpolation\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    # Get image path from column 'path' in dataframe\n",
    "    img_path = str(self.dataframe.iloc[ix]['path'])\n",
    "    # Load image\n",
    "    img_cv = cv2.imread(img_path)\n",
    "    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "    # Resize image\n",
    "    if self.dim is not None:\n",
    "      if self.dim != 3000:\n",
    "        img_cv_res = cv2.resize(img_cv, dsize=(self.dim, self.dim), interpolation=self.interpolation)\n",
    "      else:\n",
    "        img_cv_res = img_cv\n",
    "    else:\n",
    "      img_cv_res = img_cv\n",
    "    # Normalize image\n",
    "    img_cv_res_norm = img_cv_res / 255.0\n",
    "    # Convert to tensor\n",
    "    img_tensor = torch.from_numpy(img_cv_res_norm).float().permute(2, 0, 1)\n",
    "\n",
    "    # Get image height and width\n",
    "    img_height = int(self.dataframe.iloc[ix]['img_height'])\n",
    "    img_width = int(self.dataframe.iloc[ix]['img_width'])\n",
    "    \n",
    "    return img_tensor, img_height, img_width\n",
    "\n",
    "dataset = Dataset(train_df, dim = DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model load into GPU\n"
     ]
    }
   ],
   "source": [
    "model_path = models_path / \"07_unet_resnet50_DataParallel.pth\"\n",
    "with open(model_path, 'rb') as f:\n",
    "    model = load(f)\n",
    "    if GPU:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model.to(device)\n",
    "if next(model.parameters()).is_cuda:\n",
    "    print(\"Model load into GPU\")\n",
    "    GPU = True\n",
    "else:\n",
    "    print(\"Model load into CPU\")\n",
    "    GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataloader, interpolation=cv2.INTER_LANCZOS4):\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    bar = tqdm(dataloader)\n",
    "    model.eval()\n",
    "    result = []\n",
    "    scale = {'height':[],'width':[]}\n",
    "    with torch.no_grad():\n",
    "        for imgs, imgs_height, imgs_width in bar:\n",
    "            # X and y to device\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # Compute prediction\n",
    "            pred_masks = model(imgs)\n",
    "\n",
    "            # Pass from one hot to tensor\n",
    "            pred_masks = torch.argmax(pred_masks, axis=1).unsqueeze(0).type(torch.float32)\n",
    "\n",
    "            scale['height'].extend(imgs_height)\n",
    "            scale['width'].extend(imgs_width)\n",
    "            result.extend(pred_masks.detach().cpu().numpy())\n",
    "    return result, scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEARCH_BS:\n",
    "    def list_of_posible_batch_sizes(dataset):\n",
    "        batch_sizes = []\n",
    "        batch_size = 1\n",
    "        while batch_size < 2*len(dataset):\n",
    "            batch_sizes.append(batch_size)\n",
    "            batch_size *= 2\n",
    "        batch_sizes.sort(reverse=True)\n",
    "        return batch_sizes\n",
    "\n",
    "    BSs = list_of_posible_batch_sizes(dataset)\n",
    "    BSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEARCH_BS:\n",
    "    for batchsize_find in BSs:\n",
    "        print(f\"batch size: {batchsize_find}\")\n",
    "        bs_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchsize_find, shuffle=True, pin_memory=False, num_workers=4)\n",
    "        epochs = 3\n",
    "        out_of_memory = False\n",
    "        for t in range(epochs):\n",
    "            print(f\"\\tTrain epoch {t} of {epochs}\")\n",
    "            try:\n",
    "                inference(model, bs_dataloader)\n",
    "            except Exception as e:\n",
    "                print(f'Error: {e}')\n",
    "                out_of_memory = True\n",
    "                break\n",
    "        if out_of_memory == False:\n",
    "            break\n",
    "        print()\n",
    "    print(f\"Done!, bacth size is {batchsize_find}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEARCH_BS:\n",
    "    BS = batchsize_find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BS, shuffle=False, pin_memory=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:09<00:00, 36.56it/s]\n"
     ]
    }
   ],
   "source": [
    "result, scale = inference(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 1, 300, 300)\n",
      "(1, 300, 300) (300, 300) <class 'numpy.ndarray'> float32\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "El Kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. Revise el código de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener más detalles."
     ]
    }
   ],
   "source": [
    "result = np.array(result)\n",
    "print(result.shape)\n",
    "rle = []\n",
    "for i,img in enumerate(result):\n",
    "    print(img.shape, img.squeeze().shape, type(img), img.dtype)\n",
    "    mask = cv2.resize(img, dsize=(int(scale['width'][i]),int(scale['height'][i])), fx = 1, fy = 1, interpolation = cv2.INTER_LINEAR)\n",
    "    # img_c= cv2.resize(img_cv,        dsize=(self.dim, self.dim),                                             interpolation=self.interpolation)\n",
    "    mask  = np.where(mask>0.5,1,0)\n",
    "    rle.append(mask2rle(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10044.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10274.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10392.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10488.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10610</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/train_images/10610.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     organ data_source  img_height  img_width  pixel_size  \\\n",
       "0  10044  prostate         HPA        3000       3000         0.4   \n",
       "1  10274  prostate         HPA        3000       3000         0.4   \n",
       "2  10392    spleen         HPA        3000       3000         0.4   \n",
       "3  10488      lung         HPA        3000       3000         0.4   \n",
       "4  10610    spleen         HPA        3000       3000         0.4   \n",
       "\n",
       "   tissue_thickness rle   age     sex                             path  \n",
       "0                 4   0  37.0    Male  ../data/train_images/10044.tiff  \n",
       "1                 4   1  76.0    Male  ../data/train_images/10274.tiff  \n",
       "2                 4   2  82.0    Male  ../data/train_images/10392.tiff  \n",
       "3                 4   3  78.0    Male  ../data/train_images/10488.tiff  \n",
       "4                 4   4  21.0  Female  ../data/train_images/10610.tiff  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['rle'] = rle\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10488</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id rle\n",
       "0  10044   0\n",
       "1  10274   1\n",
       "2  10392   2\n",
       "3  10488   3\n",
       "4  10610   4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = train_df[['id', 'rle']]\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(output_path / \"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('HuBMAP_HPA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5908be7129383694b4ff55a3fd43a54e78208ed305dac25c0e93bbd971e0eb3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
