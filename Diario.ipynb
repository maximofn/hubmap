{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 custom unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace un primer entrenamiento con una UNet desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 custom unet DataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite el cuaderno anterior, pero intentanto distribuir el entrenamiento en 2 GPUs. Se crea ademas un script de python que hace lo mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 custom unet DistributedDataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite eñ cuaderno anterior pero entrenando en 2 GPUs con DistributedDataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 mask to rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuaderno con el que compruebo con el dataframe de entrenamiento, si la función que tengo para calcular el rle funciona bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Inference train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook en el que se prueba la inferencia con el dataset de train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Submision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook donde se crea el notebook que se subirá a Kaggle para hacer la submision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 Resnet 18 DataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook donde se crea la UNet a partir de una Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 Resnet18 finders and fastprogress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añade la búsqueda del batch size, del learning rate. Además se hace el split entre el dataset de train y validation en torno al órgano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 Resnet50 smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usa la librería `segmentation models pytorch` para entrenar el modelo con una Resnet50 como encoder. Además se añade el early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Resnet50 one class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia el modelo para que la máscara solo tenga una dimensión. Antes tenía una dimensión, si no había celula maligna una dimensión tenía un 1 y la otra un 0 y viceversa. Ahora si una célula es maligna se tiene un 1 y si no un 0\n",
    "\n",
    "Resultados modelo grande:\n",
    " * Best model epoch: 379, dice: 0.5999560475349426\n",
    " * Early stopping epoch: 116, dice: 0.5807791113853454\n",
    " * Final model epoch: 399, dice: 0.5791541814804078\n",
    "\n",
    "Se obtiene peor métrica, se descarta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mete data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 efficientnet-b7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 efficientnet-b7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelvo a probar con una efficientnet-b7, pero a raiz del cuaderno 09 que es con el que he sacado mejor puntuación. Por si he metido algún bug en algún cuaderno entre medias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 Resnet 50 gradient accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He probado dos veces con una efficientnet-b7, la segunda a partir de cuaderno 09 por si había metido algún bug, pero en los dos me daba el mismo resultado. Además he obtenido mejor resultado con una resnet50.\n",
    "Con una efficientnet-b7 he tenido que bajar mucho el tamaño de las imágenes, de normal son de unos 3000x3000, con una resnet 50 las bajé a 1300x1300 y con la efficientnet las bajé a unos 625x625.\n",
    "Así que supongo que afecta más el tamaño de la imagen que la red, por lo que vuelvo a la resnet 50 e implemento la acumulación del gradiente. Así subo las imágenes a 1900x1900 y simulo un BS de 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Futuras pruebas\n",
    " * Subir el lr al inicio, hasta llegar a un máximo y luego ir bajándolo\n",
    " * ~~Comprobar si hay algunas capas congeladas~~ No hay capas congeladas\n",
    " * ~~Investigar si se puede mejorar algo de la librería smp~~\n",
    " * Entrenamientos sucesivos con imágenes en tamaños de menos a más\n",
    " * ¿Probar otras transformaciones?\n",
    " * Cambiar el valor del lr en función de la profundidaz de las capas\n",
    " * Congelar el encoder, entrenar solo el decoder, descongelar el decoder y entrenar todo\n",
    " * ~~Acumulación del gradiente~~\n",
    " * Probar con redes más grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba commit por ssh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('HuBMAP_HPA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5908be7129383694b4ff55a3fd43a54e78208ed305dac25c0e93bbd971e0eb3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
